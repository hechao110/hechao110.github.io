<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>Sqoop | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Sqoop一 简介Apache Sqoop是在Hadoop生态体系和RDBMS体系之间传送数据的一种工具。  Sqoop工作机制是将导入或导出命令翻译成mapreduce程序来实现。在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。 Hadoop生态系统包括：HDFS、Hive、Hbase等 RDBMS体系包括(关系型数据库)：Mysql、Oracle">
<meta property="og:type" content="article">
<meta property="og:title" content="Sqoop">
<meta property="og:url" content="http://yoursite.com/2019/08/08/Sqoop/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Sqoop一 简介Apache Sqoop是在Hadoop生态体系和RDBMS体系之间传送数据的一种工具。  Sqoop工作机制是将导入或导出命令翻译成mapreduce程序来实现。在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。 Hadoop生态系统包括：HDFS、Hive、Hbase等 RDBMS体系包括(关系型数据库)：Mysql、Oracle">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-08-08T03:48:17.040Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Sqoop">
<meta name="twitter:description" content="Sqoop一 简介Apache Sqoop是在Hadoop生态体系和RDBMS体系之间传送数据的一种工具。  Sqoop工作机制是将导入或导出命令翻译成mapreduce程序来实现。在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。 Hadoop生态系统包括：HDFS、Hive、Hbase等 RDBMS体系包括(关系型数据库)：Mysql、Oracle">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Sqoop" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/08/08/Sqoop/" class="article-date">
  <time datetime="2019-08-08T03:41:25.000Z" itemprop="datePublished">2019-08-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Sqoop
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h1><h1 id="一-简介"><a href="#一-简介" class="headerlink" title="一 简介"></a>一 简介</h1><p>Apache Sqoop是在Hadoop生态体系和RDBMS体系之间传送数据的一种工具。</p>
<p> Sqoop工作机制是将导入或导出命令翻译成mapreduce程序来实现。在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。</p>
<p>Hadoop生态系统包括：HDFS、Hive、Hbase等</p>
<p>RDBMS体系包括(关系型数据库)：Mysql、Oracle、DB2等</p>
<p>Sqoop也可以理解为：“SQL 到 Hadoop 和 Hadoop 到SQL”。</p>
<p>站在Apache的立场数据可以分为导入和导出:</p>
<p>Import：数据导入。RDBMS—–&gt;Hadoop</p>
<p>Export：数据导出。Hadoop—-&gt;RDBMS</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>前提: 安装过java和Hadoop</p>
<p>版本 1.4.6</p>
<p>解压及安装</p>
<p>配置sqoop中的conf中的</p>
<p>mv sqoop-env-template.sh sqoop-env.sh</p>
<p>vi sqoop-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_COMMON_HOME= /export/servers/hadoop-2.7.5 </span><br><span class="line">export HADOOP_MAPRED_HOME= /export/servers/hadoop-2.7.5</span><br><span class="line">export HIVE_HOME= /export/servers/hive</span><br><span class="line">##还可以配置hbase等</span><br></pre></td></tr></table></figure>

<p>把数据库的驱动加入 sqoop的lib中</p>
<p>测试:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop list-databases --connect jdbc:mysql://node03:3306/ --username root --password 123456</span><br></pre></td></tr></table></figure>

<p>本命令会列出所有(mysql)(orole)等的数据库。</p>
<h1 id="二-sqoop的导入"><a href="#二-sqoop的导入" class="headerlink" title="二 sqoop的导入"></a>二 sqoop的导入</h1><h2 id="1-从数据库导入hdfs"><a href="#1-从数据库导入hdfs" class="headerlink" title="1 从数据库导入hdfs"></a>1 从数据库导入hdfs</h2><ul>
<li>mysql的地址尽量不要使用localhost 请使用ip或者host</li>
<li>如果不指定 导入到hdfs默认分隔符是 “,”</li>
<li>可以通过– fields-terminated-by ‘\ t‘ 指定具体的分隔符</li>
<li>如果表的数据比较大 可以并行启动多个maptask执行导入操作，如果表没有主键，请指定根据哪个字段进行切分</li>
</ul>
<p>全量导入</p>
<p><strong>若是换行 每行结尾必须加 \ 否则报错</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /sqoopresult1 \   ##指定存在hdfs的目录</span><br><span class="line">--table emp --m 1   ###指定要导入的表  并指定要运行几个MapTask --m 1</span><br></pre></td></tr></table></figure>

<p>指定分隔符导入 sqoop的默认分隔符为 “,”</p>
<p>–fields-terminated-by ‘\t’ \ ##指定存在hdfs 上的文件的分隔符</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /sqoopresout2 \</span><br><span class="line">--fields-terminated-by &apos;\t&apos; \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>

<p>指定分割字段和启动几个MapReduce</p>
<p>sqoop命令中，–split-by<br>id通常配合-m 10参数使用。用于指定根据哪个字段进行划分并启动多少个maptask。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /sqoopresult214 \</span><br><span class="line">--fields-terminated-by &apos;\t&apos; \</span><br><span class="line">--split-by id \                 ##指定分割字段</span><br><span class="line">--table emp --m 2               ##--m 2 启动两个maptask</span><br></pre></td></tr></table></figure>

<p>##2从数据库导入hive</p>
<p>全量导入</p>
<h3 id="1将表结构复制到hive中"><a href="#1将表结构复制到hive中" class="headerlink" title="1将表结构复制到hive中"></a>1将表结构复制到hive中</h3><p>hive 中的数据库为test 必须存在 emp_add_sp表 可以不存在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop create-hive-table \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table emp_add \</span><br><span class="line">--hive-table test.emp_add_sp</span><br></pre></td></tr></table></figure>

<p>从关系数据库导入文件到hive中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table emp_add \</span><br><span class="line">--hive-table test.emp_add_sp \</span><br><span class="line">--hive-import \</span><br><span class="line">--m 1</span><br></pre></td></tr></table></figure>

<h3 id="2直接从数据库导入数据到hive中-包括表结构和数据"><a href="#2直接从数据库导入数据到hive中-包括表结构和数据" class="headerlink" title="2直接从数据库导入数据到hive中 包括表结构和数据"></a>2直接从数据库导入数据到hive中 包括表结构和数据</h3><p>不用指定hive的表名,会根据数据库的表名自动创建 若test库不存在会在root下创建表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table emp_conn \</span><br><span class="line">--hive-import \</span><br><span class="line">--m 1 \</span><br><span class="line">--hive-database test</span><br></pre></td></tr></table></figure>

<p>##3导入表数据子集(导入hdfs)</p>
<h3 id="1where条件过滤导入"><a href="#1where条件过滤导入" class="headerlink" title="1where条件过滤导入"></a>1where条件过滤导入</h3><p>–where可以指定从关系数据库导入数据时的查询条件。它执行在数据库服务器相应的SQL查询，并将结果存储在HDFS的目标目录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--where &quot;city=&apos;sec-bad&apos;&quot; \</span><br><span class="line">--target-dir /wherequery \</span><br><span class="line">--table emp_add \</span><br><span class="line">--m 1</span><br></pre></td></tr></table></figure>

<p>###2query查询过滤导入</p>
<p>使用 query sql 语句来进行查找不能加参数–table ;<br>并且必须要添加 where 条件;<br>并且 where 条件后面必须带一个$CONDITIONS 这个字符串;<br>并且这个 sql 语句必须用单引号，不能用双引号;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /query1 \</span><br><span class="line">--query &apos;select id,name,deg from emp where id&gt;1203 and $CONDITIONS&apos; \</span><br><span class="line">--split-by id \</span><br><span class="line">--fields-terminated-by &apos;\001&apos; \</span><br><span class="line">--m 2</span><br></pre></td></tr></table></figure>

<p>sqoop命令中–split-by id通常配合-m 10参数使用。<br>首先sqoop会向关系型数据库比如mysql发送一个命令:select max(id),min(id) from test。<br>然后会把max、min之间的区间平均分为10分，最后10个并行的map去找数据库，导数据就正式开始。</p>
<h2 id="4增量导入"><a href="#4增量导入" class="headerlink" title="4增量导入"></a>4增量导入</h2><h3 id="1-Append-模式"><a href="#1-Append-模式" class="headerlink" title="1 Append,模式"></a>1 Append,模式</h3><p>就是追加导入,在原有的基础上 <strong>根据数值类型字段进行追加导入 大于指定的last-value</strong></p>
<p>例子</p>
<p>先把数据库数据导入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /appendresult \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>

<p>在数据库emp 中在插入两条数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert into `userdb`.`emp` (`id`, `name`, `deg`, `salary`, `dept`) values (&apos;1206&apos;, &apos;allen&apos;, &apos;admin&apos;, &apos;30000&apos;, &apos;tp&apos;);</span><br><span class="line">insert into `userdb`.`emp` (`id`, `name`, `deg`, `salary`, `dept`) values (&apos;1207&apos;, &apos;woon&apos;, &apos;admin&apos;, &apos;40000&apos;, &apos;tp&apos;);</span><br></pre></td></tr></table></figure>

<p>执行追加导入</p>
<p>–incremental append \ 增量导入的模式<br>–check-column id \ 数值类型字段进行追加导入<br>–last-value 1205 最后字段值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table emp --m 1 \</span><br><span class="line">--target-dir /appendresult \</span><br><span class="line">--incremental append \</span><br><span class="line">--check-column id \</span><br><span class="line">--last-value 1205</span><br></pre></td></tr></table></figure>

<h3 id="3-lastmodified模式"><a href="#3-lastmodified模式" class="headerlink" title="3 lastmodified模式"></a>3 lastmodified模式</h3><p>1append模式(附加)</p>
<p>lastmodified 根据时间戳类型字段进行追加 <strong>大于等于</strong>指定的last-value</p>
<ul>
<li>注意在lastmodified 模式下 还分为两种情形：append merge-key</li>
</ul>
<p>关于lastmodified 中的两种模式：</p>
<ul>
<li><p>append 只会追加增量数据到一个新的文件中 并且会产生数据的重复问题</p>
<p>因为默认是从指定的last-value 大于等于其值的数据开始导入</p>
</li>
<li><p>merge-key 把增量的数据合并到一个文件中 处理追加增量数据之外 如果之前的数据有变化修改</p>
<p>也可以进行修改操作 底层相当于进行了一次完整的mr作业。数据不会重复。</p>
</li>
</ul>
<p>数据库建表:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table customertest(id int,name varchar(20),last_mod timestamp default current_timestamp on update current_timestamp);</span><br><span class="line">此处的时间戳设置为在数据的产生和更新时都会发生改变.</span><br></pre></td></tr></table></figure>

<p>插入数据(一个一个插,可以保证last_mod 字段不一样)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">insert into customertest(id,name) values(1,&apos;neil&apos;);</span><br><span class="line">insert into customertest(id,name) values(2,&apos;jack&apos;);</span><br><span class="line">insert into customertest(id,name) values(3,&apos;martin&apos;);</span><br><span class="line">insert into customertest(id,name) values(4,&apos;tony&apos;);</span><br><span class="line">insert into customertest(id,name) values(5,&apos;eric&apos;);</span><br></pre></td></tr></table></figure>

<p>执行命令导入hdfs:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /lastmodifiedresult \</span><br><span class="line">--table customertest --m 1</span><br></pre></td></tr></table></figure>

<p>在mysql中在插入一条数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into customertest(id,name) values(6,&apos;james&apos;)</span><br></pre></td></tr></table></figure>

<p>使用增量导入:</p>
<p>三兄弟:两种导入都要写</p>
<p>–check-column last_mod<br>–incremental lastmodified<br>–last-value “2019-06-05 15:52:58” \</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table customertest \</span><br><span class="line">--target-dir /lastmodifiedresult \</span><br><span class="line">--check-column last_mod \</span><br><span class="line">--incremental lastmodified \</span><br><span class="line">--last-value &quot;2019-06-05 15:52:58&quot; \</span><br><span class="line">--m 1 \</span><br><span class="line">--append    #追加方式  merge-key 和append</span><br></pre></td></tr></table></figure>

<p>查看结果发现:</p>
<p>此处已经会导入我们最后插入的一条记录,但是我们却发现此处插入了2条数据，这是为什么呢？<br>这是因为采用lastmodified模式去处理增量时，会将大于等于last-value值的数据当做增量插入</p>
<p>注意:<br>*<em>使用lastmodified模式进行增量处理要指定增量数据是以append模式(附加)还是merge-key(合并)模式添加 *</em></p>
<p>2merge-key模式(合并)</p>
<p>数据库操作:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update customertest set name = &apos;Neil&apos; where id = 1;</span><br></pre></td></tr></table></figure>

<p>增量导入:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table customertest \</span><br><span class="line">--target-dir /lastmodifiedresult \</span><br><span class="line">--check-column last_mod \</span><br><span class="line">--incremental lastmodified \</span><br><span class="line">--last-value &quot;2019-06-05 15:52:58&quot; \</span><br><span class="line">--m 1 \</span><br><span class="line">--merge-key id</span><br></pre></td></tr></table></figure>

<p>由于merge-key模式是进行了一次完整的mapreduce操作，因此最终我们在lastmodifiedresult文件夹下可以看到生成的为part-r-00000这样的文件，会发现id=1的name已经得到修改，同时新增了id=6的数据。</p>
<h1 id="三sqoop导出"><a href="#三sqoop导出" class="headerlink" title="三sqoop导出"></a>三sqoop导出</h1><p>将数据从Hadoop生态体系导出到RDBMS数据库导出前，目标表必须存在于目标数据库中。</p>
<p>export有三种模式：</p>
<p>默认操作: 是从将文件中的数据使用INSERT语句插入到表中。若为空表底层为insert一条一条的插入</p>
<p>更新模式：Sqoop将生成UPDATE替换数据库中现有记录的语句。底层为updata</p>
<p>调用模式：Sqoop将为每条记录创建一个存储过程调用。</p>
<p>配置参数:</p>
<ul>
<li>导出文件的分隔符 如果不指定 默认以“,”去切割读取数据文件 –input-fields-terminated-by</li>
<li>如果文件的字段顺序和表中顺序不一致 需要–columns 指定 多个字段之间以”,”</li>
<li>导出的时候需要指定导出数据的目的 export-dir 和导出到目标的表名或者存储过程名</li>
<li>针对空字符串类型和非字符串类型的转换 “\n”</li>
</ul>
<h2 id="1-默认模式导出HDFS数据到mysql"><a href="#1-默认模式导出HDFS数据到mysql" class="headerlink" title="1 默认模式导出HDFS数据到mysql"></a>1 默认模式导出HDFS数据到mysql</h2><p>默认情况下，sqoop export将每行输入记录转换成一条INSERT语句，添加到目标数据库表中。如果数据库中的表具有约束条件（例如，其值必须唯一的主键列）并且已有数据存在，则必须注意避免插入违反这些约束条件的记录。如果INSERT语句失败，导出过程将失败。<strong>此模式主要用于将记录导出到可以接收这些结果的空表中</strong>。通常用于全表数据导出。</p>
<p>导出时可以是将Hive表中的全部记录或者HDFS数据（可以是全部字段也可以部分字段）导出到Mysql目标表。</p>
<p>1准备hdfs数据</p>
<p>在HDFS文件系统中“/emp/”目录的下创建一个文件emp_data.txt：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1201,gopal,manager,50000,TP</span><br><span class="line">1202,manisha,preader,50000,TP</span><br><span class="line">1203,kalil,php dev,30000,AC</span><br><span class="line">1204,prasanth,php dev,30000,AC</span><br><span class="line">1205,kranthi,admin,20000,TP</span><br><span class="line">1206,satishp,grpdes,20000,GR</span><br></pre></td></tr></table></figure>

<p>2手动创建数据库中的表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE userdb;</span><br><span class="line">mysql&gt; CREATE TABLE employee ( </span><br><span class="line">   id INT NOT NULL PRIMARY KEY, </span><br><span class="line">   name VARCHAR(20), </span><br><span class="line">   deg VARCHAR(20),</span><br><span class="line">   salary INT,</span><br><span class="line">   dept VARCHAR(10));</span><br></pre></td></tr></table></figure>

<p>3执行导出命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table employee \</span><br><span class="line">--export-dir /emp/</span><br></pre></td></tr></table></figure>

<p>若是数据库中字段与emp_data.txt文件中字段类型一致,上述做法可以 若不一致</p>
<p>当导出数据文件和目标表字段列顺序完全一致的时候上述做法可以 若不一致。以逗号为间隔选择和排列各个列。加一下配置</p>
<p>–columns id,name,deg,salary,dept \ 指定emp_data.txt 中个字段的名字</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table employee1 \</span><br><span class="line">--columns id,name,deg,salary,dept \</span><br><span class="line">--export-dir /emp/</span><br></pre></td></tr></table></figure>

<p>–input-fields-terminated-by ‘\t’</p>
<p>指定文件中的分隔符</p>
<p>–columns</p>
<p>选择列并控制它们的排序。当导出数据文件和目标表字段列顺序完全一致的时候可以不写。否则以逗号为间隔选择和排列各个列。没有被包含在–columns后面列名或字段要么具备默认值，要么就允许插入空值。否则数据库会拒绝接受sqoop导出的数据，导致Sqoop作业失败</p>
<p>–export-dir 导出目录，在执行导出的时候，必须指定这个参数，同时需要具备–table或–call参数两者之一，–table是指的导出数据库当中对应的表，</p>
<p>–call是指的某个存储过程。</p>
<p>–input-null-string –input-null-non-string</p>
<p>如果没有指定第一个参数，对于字符串类型的列来说，“NULL”这个字符串就回被翻译成空值，如果没有使用第二个参数，无论是“NULL”字符串还是说空字符串也好，对于非字符串类型的字段来说，这两个类型的空串都会被翻译成空值。比如：</p>
<p>–input-null-string “\N” –input-null-non-string “\N”</p>
<h2 id="2更新导出（updateonly模式）"><a href="#2更新导出（updateonly模式）" class="headerlink" title="2更新导出（updateonly模式）"></a>2更新导出（updateonly模式）</h2><p>– update-key，更新标识，即根据某个字段进行更新，例如id，可以指定多个更新标识的字段，多个字段之间用逗号分隔。</p>
<p>– updatemod，指定updateonly（默认模式），<strong>仅仅更新已存在的数据记录，不会插入新纪录。</strong></p>
<p>在HDFS文件系统中“/updateonly_1/”目录的下创建一个文件updateonly_1.txt：<br>1201,gopal,manager,50000<br>1202,manisha,preader,50000<br>1203,kalil,php dev,30000</p>
<p>手动创建mysql中的目标表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE userdb;</span><br><span class="line">mysql&gt; CREATE TABLE updateonly ( </span><br><span class="line">   id INT NOT NULL PRIMARY KEY, </span><br><span class="line">   name VARCHAR(20), </span><br><span class="line">   deg VARCHAR(20),</span><br><span class="line">   salary INT);</span><br></pre></td></tr></table></figure>

<p>先执行全部导出操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table updateonly \</span><br><span class="line">--export-dir /updateonly_1/</span><br></pre></td></tr></table></figure>

<p>新增一个文件updateonly_2.txt：修改了前三条数据并且新增了一条记录<br>1201,gopal,manager,1212<br>1202,manisha,preader,1313<br>1203,kalil,php dev,1414<br>1204,allen,java,1515</p>
<p>hadoop fs -put updateonly_2.txt /updateonly_2</p>
<p>执行更新导出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table updateonly \</span><br><span class="line">--export-dir /updateonly_2/ \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode updateonly</span><br></pre></td></tr></table></figure>

<h2 id="3-更新导出（allowinsert模式）"><a href="#3-更新导出（allowinsert模式）" class="headerlink" title="3 更新导出（allowinsert模式）"></a>3 更新导出（allowinsert模式）</h2><p>– update-key，更新标识，即根据某个字段进行更新，例如id，可以指定多个更新标识的字段，多个字段之间用逗号分隔。</p>
<p>– updatemod，指定allowinsert，更新已存在的数据记录，同时插入新纪录。<strong>实质上是一个insert &amp; update的操作。</strong></p>
<p>在HDFS “/allowinsert_1/”目录的下创建一个文件allowinsert_1.txt：<br>1201,gopal,manager,50000<br>1202,manisha,preader,50000<br>1203,kalil,php dev,30000</p>
<p>手动创建mysql中的目标表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE userdb;</span><br><span class="line">mysql&gt; CREATE TABLE allowinsert ( </span><br><span class="line">   id INT NOT NULL PRIMARY KEY, </span><br><span class="line">   name VARCHAR(20), </span><br><span class="line">   deg VARCHAR(20),</span><br><span class="line">   salary INT);</span><br></pre></td></tr></table></figure>

<p>先执行全部导出操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table allowinsert \</span><br><span class="line">--export-dir /allowinsert_1/</span><br></pre></td></tr></table></figure>

<p>allowinsert_2.txt。修改了前三条数据并且新增了一条记录。上传至/ allowinsert_2/目录下：<br>1201,gopal,manager,1212<br>1202,manisha,preader,1313<br>1203,kalil,php dev,1414<br>1204,allen,java,1515</p>
<p>执行更新导出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root --password 123456 \</span><br><span class="line">--table allowinsert \</span><br><span class="line">--export-dir /allowinsert_2/ \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode allowinsert</span><br></pre></td></tr></table></figure>

<h1 id="四sqoop-job-作业"><a href="#四sqoop-job-作业" class="headerlink" title="四sqoop job 作业"></a>四sqoop job 作业</h1><h2 id="1-job-语法"><a href="#1-job-语法" class="headerlink" title="1 job 语法"></a>1 job 语法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sqoop job (generic-args) (job-args)</span><br><span class="line">   [-- [subtool-name] (subtool-args)]</span><br><span class="line"></span><br><span class="line">$ sqoop-job (generic-args) (job-args)</span><br><span class="line">   [-- [subtool-name] (subtool-args)]</span><br></pre></td></tr></table></figure>

<h2 id="2-创建job"><a href="#2-创建job" class="headerlink" title="2 创建job"></a>2 创建job</h2><p>在这里，我们创建一个名为jobtest，这可以从RDBMS表的数据导入到HDFS作业。</p>
<p>下面的命令用于创建一个从DB数据库的emp表导入到HDFS文件的作业。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --create jobtest -- import --connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /sqoopresult333 \</span><br><span class="line">--table emp --m 1</span><br><span class="line"></span><br><span class="line">注意import前要有空格</span><br></pre></td></tr></table></figure>

<h2 id="3-验证job"><a href="#3-验证job" class="headerlink" title="3 验证job"></a>3 验证job</h2><p><strong>–list’</strong> 参数是用来验证保存的作业。下面的命令用来验证保存Sqoop作业的列表。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --list</span><br></pre></td></tr></table></figure>

<h2 id="4检查job"><a href="#4检查job" class="headerlink" title="4检查job"></a>4检查job</h2><p><strong>‘–show’</strong> 参数用于检查或验证特定的工作，及其详细信息。以下命令和样本输出用来验证一个名为jobtest的作业。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --show jobtest</span><br></pre></td></tr></table></figure>

<h2 id="5-执行job"><a href="#5-执行job" class="headerlink" title="5 执行job"></a>5 执行job</h2><p><strong>‘–exec’</strong> 选项用于执行保存的作业。下面的命令用于执行保存的作业称为jobtest。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --exec jobtest</span><br></pre></td></tr></table></figure>

<h2 id="6免密执行job"><a href="#6免密执行job" class="headerlink" title="6免密执行job"></a>6免密执行job</h2><p>sqoop在创建job时，使用–password-file参数，可以避免输入mysql密码，如果使用–password将出现警告，并且每次都要手动输入密码才能执行job，sqoop规定密码文件必须存放在HDFS上，并且权限必须是400。</p>
<p>并且检查sqoop的sqoop-site.xml是否存在如下配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;name&gt;sqoop.metastore.client.record.password&lt;/name&gt;</span><br><span class="line"></span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line"></span><br><span class="line">    &lt;description&gt;If true, allow saved passwords in the metastore.</span><br><span class="line"></span><br><span class="line">    &lt;/description&gt;</span><br><span class="line"></span><br><span class="line">&lt;/property&gt;</span><br><span class="line">bin/sqoop job --create jobtest -- import --connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password-file /input/sqoop/pwd/mysqltest.pwd \</span><br><span class="line">--target-dir /sqoopresult333 \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/08/08/Sqoop/" data-id="cjz257yxk000cbcu5k1035nft" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/08/08/Flume/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Flume
        
      </div>
    </a>
  
  
    <a href="/2019/08/08/Azkaban/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Azkaban</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/08/08/Hive/">Hive</a>
          </li>
        
          <li>
            <a href="/2019/08/08/Flume/">Flume</a>
          </li>
        
          <li>
            <a href="/2019/08/08/Sqoop/">Sqoop</a>
          </li>
        
          <li>
            <a href="/2019/08/08/Azkaban/">Azkaban</a>
          </li>
        
          <li>
            <a href="/2019/08/08/Impala/">Impala</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>