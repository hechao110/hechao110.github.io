<!DOCTYPE html><html lang="hc-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="一只沙皮狗的悲伤"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style-dark.css?v=2.0.4"><link rel="stylesheet" type="text/css" href="/css/highlight-dark.css?v=2.0.4"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>Storm | 一只沙皮狗的悲伤</title></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Storm</h1><a id="logo" href="/.">一只沙皮狗的悲伤</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Suche"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Storm</h1><div class="post-meta"><a href="/2017/06/24/Storm/#comments" class="comment-count"></a><p><span class="date">Jun 24, 2017</span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>Schlägt</i></i></span></p></div><div class="post-content"><h1 id="离线处理与实时处理"><a href="#离线处理与实时处理" class="headerlink" title="离线处理与实时处理"></a>离线处理与实时处理</h1><p><strong>离线处理方面Hadoop提供了很好的解决方案，但是针对海量数据的实时处理却一直没有比较好的解决方案</strong></p>
<h2 id="1-1-实现实时计算系统需要解决那些问题"><a href="#1-1-实现实时计算系统需要解决那些问题" class="headerlink" title="1.1 实现实时计算系统需要解决那些问题"></a>1.1 实现实时计算系统需要解决那些问题</h2><p>如果让我们自己设计一个实时计算系统，我们要解决哪些问题。</p>
<p>（1）低延迟：都说了是实时计算系统了，延迟是一定要低的。</p>
<p>（2）高性能：性能不高就是浪费机器，浪费机器是要受批评的哦。</p>
<p>（3）分布式：系统都是为应用场景而生的，如果你的应用场景、你的数据和计算单机就能搞定，那么不用考虑这些复杂的问题了。我们所说的是单机搞不定的情况。</p>
<p>（4）可扩展：伴随着业务的发展，我们的数据量、计算量可能会越来越大，所以希望这个系统是可扩展的。</p>
<p>（5）容错：这是分布式系统中通用问题。一个节点挂了不能影响我的应用。</p>
<p>（6）通信：设计的系统需要应用程序开发人员考虑各个处理组件的分布、消息的传递吗？如果是，发人员可能会用不好，也不会想去用。</p>
<p>（7）<strong>消息不丢失：用户发布的一个宝贝消息不能在实时处理的时候给丢了</strong>，对吧？</p>
<h2 id="1-1-离线计算是什么"><a href="#1-1-离线计算是什么" class="headerlink" title="1.1 离线计算是什么"></a>1.1 <strong>离线计算是什么</strong></h2><p>离线计算：批量获取数据、批量传输数据、<strong>周期性</strong>批量计算数据、数据展示</p>
<p> 代表技术：Sqoop批量导入数据、HDFS批量存储数据、MapReduce批量计算数据、Hive批量计算数据、***任务调度</p>
<p>日常业务：</p>
<p>1，hivesql</p>
<p>2、调度平台</p>
<p>3、Hadoop集群运维</p>
<p>4、数据清洗（脚本语言）</p>
<p>5、元数据管理</p>
<p>6、数据稽查</p>
<p>7、数据仓库模型架构</p>
<h2 id="流式计算是什么"><a href="#流式计算是什么" class="headerlink" title="流式计算是什么"></a>流式计算是什么</h2><p> 流式计算：数据实时产生、数据实时传输、数据实时计算、实时展示</p>
<p> 代表技术：Flume实时获取数据、Kafka/<strong>metaq</strong>实时数据存储、<strong>Storm/JStorm</strong>实时数据计算、Redis实时<strong>结果</strong>缓存、持久化存储(mysql)。</p>
<p> 一句话总结：将源源不断产生的数据实时收集并实时计算，尽可能快的得到计算结果，用来支持决策。</p>
<h2 id="离线计算与实时计算的区别"><a href="#离线计算与实时计算的区别" class="headerlink" title="离线计算与实时计算的区别"></a>离线计算与实时计算的区别</h2><p>最大的区别：实时收集、实时计算、实时展示</p>
<p>离线计算，一次计算很多条数据</p>
<p>实时计算，数据被一条一条的计算</p>
<h2 id="一概述"><a href="#一概述" class="headerlink" title="一概述"></a>一概述</h2><p>Apache Strom 流式计算框架</p>
<p>Hadoop处理数据时效性不够,Strom能够尽快得到处理后的数据</p>
<p>Strom只负责数据计算,不负责数据存储</p>
<p>一般是kafka的消费者 然后把数据存入Redis</p>
<p><strong>用处</strong></p>
<p>1日志分析，从海量日志中分析出特定的数据，并将分析的结果存入外部存储器用来辅佐决策。</p>
<p>2管道系统， 将一个数据从一个系统传输到另外一个系统， 比如将数据库同步到Hadoop</p>
<p>3消息转化器， 将接受到的消息按照某种格式进行转化，存储到另外一个系统如消息中间件</p>
<p>4统计分析器， 从日志或消息中，提炼出某个字段，然后做count或sum计算，最后将统计值存入外部存储器。中间处理过程可能更复杂。</p>
<h2 id="二-架构"><a href="#二-架构" class="headerlink" title="二 架构"></a>二 架构</h2><p><strong>1主从架构</strong></p>
<p><a href="https://manzhong.github.io/images/storm/jg.png" target="_blank" rel="noopener"><img src="https://manzhong.github.io/images/storm/jg.png" alt="img"></a></p>
<p>Nimbus：负责资源分配和任务调度。</p>
<p>Supervisor：负责接受nimbus分配的任务，启动和停止属于自己管理的worker进程。</p>
<p>Worker：运行具体处理组件逻辑的进程。</p>
<p>Task：worker中每一个spout/bolt的线程称为一个task. 在storm0.8之后，task不再与物理线程对应，同一个spout/bolt的task可能会共享一个物理线程，该线程称为executor。</p>
<p><strong>2编程模型</strong></p>
<p><a href="https://manzhong.github.io/images/storm/bcmx.png" target="_blank" rel="noopener"><img src="https://manzhong.github.io/images/storm/bcmx.png" alt="img"></a></p>
<p><strong>Topology</strong>：Storm中运行的一个实时应用程序，因为各个组件间的消息流动形成逻辑上的一个拓扑结构。</p>
<p><strong>Spout</strong>：在一个topology中产生源数据流的组件。通常情况下spout会从外部数据源(<strong>kafaka</strong>)中读取数据，然后转换为topology内部的源数据。Spout是一个主动的角色，其接口中有个nextTuple()函数，storm框架会不停地调用此函数，用户只要在其中生成源数据即可。</p>
<p><strong>Bolt</strong>：在一个topology中接受数据然后执行处理的组件。Bolt可以执行过滤、函数操作、合并、写数据库等任何操作。Bolt是一个被动的角色，其接口中有个execute(Tuple input)函数,在接受到消息后会调用此函数，用户可以在其中执行自己想要的操作。</p>
<p><strong>Tuple</strong>：一次消息传递的基本单元。本来应该是一个key-value的map，但是由于各个组件间传递的tuple的字段名称已经事先定义好，所以tuple中只要按序填入各个value就行了，所以就是一个value list.</p>
<p><strong>Stream</strong>：源源不断传递的tuple就组成了stream。</p>
<p><strong>3分组策略</strong></p>
<p>Stream grouping：即消息的partition方法。</p>
<p>Stream Grouping定义了一个流在Bolt任务间该如何被切分。这里有Storm提供的6个Stream Grouping类型：</p>
<p>\1. 随机分组(Shuffle grouping)：随机分发tuple到Bolt的任务，保证每个任务获得相等数量的tuple。 <strong>跨服务器通信，浪费网络资源，尽量不适用</strong></p>
<p>\2. 字段分组(Fields grouping)：根据指定字段分割数据流，并分组。例如，根据“user-id”字段，相同“user-id”的元组总是分发到同一个任务，不同“user-id”的元组可能分发到不同的任务。 <strong>跨服务器，除非有必要，才使用这种方式。</strong></p>
<p>\3. 全部分组(All grouping)：tuple被复制到bolt的所有任务。这种类型需要谨慎使用。 <strong>人手一份，完全不必要</strong></p>
<p>\4. 全局分组(Global grouping)：全部流都分配到bolt的同一个任务。明确地说，是分配给ID最小的那个task。 <strong>欺负新人</strong></p>
<p>\5. 无分组(None grouping)：你不需要关心流是如何分组。目前，无分组等效于随机分组。但最终，Storm将把无分组的Bolts放到Bolts或Spouts订阅它们的同一线程去执行(如果可能)。</p>
<p>\6. 直接分组(Direct grouping)：这是一个特别的分组类型。元组生产者决定tuple由哪个元组处理者任务接收。 <strong>点名分配 AckerBolt 消息容错</strong></p>
<p><strong>7.LocalOrShuffle</strong> <strong>分组。 优先将数据发送到本地的Task，节约网络通信的资源。</strong></p>
<p><strong>使用storm 进行计算</strong><br>需求:</p>
<p> 单词统计</p>
<p>依赖</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">       &lt;dependency&gt;</span><br><span class="line">           &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;</span><br><span class="line">           &lt;artifactId&gt;storm-core&lt;/artifactId&gt;</span><br><span class="line">           &lt;!-- apache storm 1.x  |  2.x jstorm和storm合并版本--&gt;</span><br><span class="line">           &lt;version&gt;1.1.1&lt;/version&gt;</span><br><span class="line">            &lt;!-- 目前&lt;scope&gt;可以使用5个值：</span><br><span class="line">   * compile，缺省值，适用于所有阶段，会随着项目一起发布。</span><br><span class="line">   * provided，类似compile，期望JDK、容器或使用者会提供这个依赖。如servlet.jar。</span><br><span class="line">   * runtime，只在运行时使用，如JDBC驱动，适用运行和测试阶段。</span><br><span class="line">   * test，只在测试时使用，用于编译和运行测试代码。不会随项目发布。</span><br><span class="line">   * system，类似provided，需要显式提供包含依赖的jar，Maven不会在Repository中查找它。  --&gt;</span><br><span class="line">       &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;</span><br><span class="line">       &lt;/dependency&gt;</span><br><span class="line">   &lt;/dependencies&gt;</span><br><span class="line">   &lt;build&gt;</span><br><span class="line">       &lt;plugins&gt;</span><br><span class="line">           &lt;plugin&gt;</span><br><span class="line">               &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">               &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class="line">               &lt;version&gt;3.7.0&lt;/version&gt;</span><br><span class="line">               &lt;configuration&gt;</span><br><span class="line">                   &lt;source&gt;1.8&lt;/source&gt;</span><br><span class="line">                   &lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">               &lt;/configuration&gt;</span><br><span class="line">           &lt;/plugin&gt;</span><br><span class="line">       &lt;/plugins&gt;</span><br><span class="line">   &lt;/build&gt;</span><br></pre></td></tr></table></figure>

<p><strong>驱动类</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.storm.Config;</span><br><span class="line">import org.apache.storm.LocalCluster;</span><br><span class="line">import org.apache.storm.StormSubmitter;</span><br><span class="line">import org.apache.storm.generated.AlreadyAliveException;</span><br><span class="line">import org.apache.storm.generated.AuthorizationException;</span><br><span class="line">import org.apache.storm.generated.InvalidTopologyException;</span><br><span class="line">import org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * wordcount的驱动类，用来提交任务的。</span><br><span class="line"> */</span><br><span class="line">public class WordCountTopology &#123;</span><br><span class="line">    public static void main(String[] args) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException &#123;</span><br><span class="line">        // 通过TopologyBuilder来封装任务信息</span><br><span class="line">        TopologyBuilder topologyBuilder = new TopologyBuilder();</span><br><span class="line">//        设置spout，获取数据</span><br><span class="line">        topologyBuilder.setSpout(&quot;readfilespout&quot;,new ReadFileSpout(),2);</span><br><span class="line">//        设置splitbolt，对句子进行切割</span><br><span class="line">        topologyBuilder.setBolt(&quot;splitbolt&quot;,new SplitBolt(),4).shuffleGrouping(&quot;readfilespout&quot;);</span><br><span class="line">//        设置wordcountbolt，对单词进行统计</span><br><span class="line">        topologyBuilder.setBolt(&quot;wordcountBolt&quot;,new WordCountBolt(),2).shuffleGrouping(&quot;splitbolt&quot;);</span><br><span class="line"></span><br><span class="line">//        准备一个配置文件</span><br><span class="line">        Config config = new Config();</span><br><span class="line">//        storm中任务提交有两种方式，一种方式是本地模式，另一种是集群模式。</span><br><span class="line">//        LocalCluster localCluster = new LocalCluster();</span><br><span class="line">//        localCluster.submitTopology(&quot;wordcount&quot;,config,topologyBuilder.createTopology());</span><br><span class="line">        //在storm集群中，worker是用来分配的资源。如果一个程序没有指定worker数，那么就会使用默认值。</span><br><span class="line">        config.setNumWorkers(2);</span><br><span class="line">        //提交到集群</span><br><span class="line">        StormSubmitter.submitTopology(&quot;wordcount1&quot;,config,topologyBuilder.createTopology());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>读取文件Spout</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line">import org.apache.storm.task.TopologyContext;</span><br><span class="line">import org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line">import org.apache.storm.tuple.Fields;</span><br><span class="line">import java.io.*;</span><br><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 读取外部的文件，将一行一行的数据发送给下游的bolt</span><br><span class="line"> * 类似于hadoop MapReduce中的inputformat</span><br><span class="line"> */</span><br><span class="line">public class ReadFileSpout extends BaseRichSpout &#123;</span><br><span class="line">    private SpoutOutputCollector collector;</span><br><span class="line">    private BufferedReader bufferedReader;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 初始化方法，类似于这个类的构造器，只被运行一次</span><br><span class="line">     * 一般用来打开数据连接，打开网络连接。</span><br><span class="line">     *</span><br><span class="line">     * @param conf      传入的是storm集群的配置文件和用户自定义配置文件，一般不用。</span><br><span class="line">     * @param context   上下文对象，一般不用</span><br><span class="line">     * @param collector 数据输出的收集器，spout类将数据发送给collector，由collector发送给storm框架。</span><br><span class="line">     */</span><br><span class="line">    public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            bufferedReader = new BufferedReader(new FileReader(new File(&quot;//data//wordcount.txt&quot;)));</span><br><span class="line">        &#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        this.collector = collector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 下一个tuple，tuple是数据传送的基本单位。</span><br><span class="line">     * 后台有个while循环一直调用该方法，每调用一次，就发送一个tuple出去</span><br><span class="line">     */</span><br><span class="line">    public void nextTuple() &#123;</span><br><span class="line">        String line = null;</span><br><span class="line">        try &#123;</span><br><span class="line">            line = bufferedReader.readLine();</span><br><span class="line">            if (line!=null)&#123;</span><br><span class="line">                collector.emit(Arrays.asList(line));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 声明发出的数据是什么</span><br><span class="line">     *</span><br><span class="line">     * @param declarer</span><br><span class="line">     */</span><br><span class="line">    public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">        declarer.declare(new Fields(&quot;juzi&quot;));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>SplitBolt</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.storm.task.OutputCollector;</span><br><span class="line">import org.apache.storm.task.TopologyContext;</span><br><span class="line">import org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">import org.apache.storm.tuple.Fields;</span><br><span class="line">import org.apache.storm.tuple.Tuple;</span><br><span class="line"></span><br><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.HashSet;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 输入：一行数据</span><br><span class="line"> * 计算：对一行数据进行切割</span><br><span class="line"> * 输出：单词及单词出现的次数</span><br><span class="line"> */</span><br><span class="line">public class SplitBolt extends BaseRichBolt&#123;</span><br><span class="line">    private  OutputCollector collector;</span><br><span class="line">    /**</span><br><span class="line">     * 初始化方法，只被运行一次。</span><br><span class="line">     * @param stormConf 配置文件</span><br><span class="line">     * @param context 上下文对象，一般不用</span><br><span class="line">     * @param collector 数据收集器</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123;</span><br><span class="line">            this.collector = collector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 执行业务逻辑的方法</span><br><span class="line">     * @param input 获取上游的数据</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void execute(Tuple input) &#123;</span><br><span class="line">        // 获取上游的句子</span><br><span class="line">        String juzi = input.getStringByField(&quot;juzi&quot;);</span><br><span class="line">        // 对句子进行切割</span><br><span class="line">        String[] words = juzi.split(&quot; &quot;);</span><br><span class="line">        // 发送数据</span><br><span class="line">        for (String word : words) &#123;</span><br><span class="line">            // 需要发送单词及单词出现的次数，共两个字段</span><br><span class="line">            collector.emit(Arrays.asList(word,&quot;1&quot;));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">        declarer.declare(new Fields(&quot;word&quot;,&quot;num&quot;));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>wordcountBolt</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.storm.task.OutputCollector;</span><br><span class="line">import org.apache.storm.task.TopologyContext;</span><br><span class="line">import org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">import org.apache.storm.tuple.Tuple;</span><br><span class="line"></span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 输入：单词及单词出现的次数</span><br><span class="line"> * 输出：打印在控制台</span><br><span class="line"> * 负责统计每个单词出现的次数</span><br><span class="line"> * 类似于hadoop MapReduce中的reduce函数</span><br><span class="line"> */</span><br><span class="line">public class WordCountBolt extends BaseRichBolt &#123;</span><br><span class="line">    private Map&lt;String, Integer&gt; wordCountMap = new HashMap&lt;String, Integer&gt;();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 初始化方法</span><br><span class="line">     *</span><br><span class="line">     * @param stormConf 集群及用户自定义的配置文件</span><br><span class="line">     * @param context   上下文对象</span><br><span class="line">     * @param collector 数据收集器</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123;</span><br><span class="line">        // 由于wordcount是最后一个bolt，所有不需要自定义OutputCollector collector，并赋值。</span><br><span class="line">    &#125;</span><br><span class="line">    @Override</span><br><span class="line">    public void execute(Tuple input) &#123;</span><br><span class="line">        //获取单词出现的信息（单词、次数）</span><br><span class="line">        String word = input.getStringByField(&quot;word&quot;);</span><br><span class="line">        String num = input.getStringByField(&quot;num&quot;);</span><br><span class="line">        // 定义map记录单词出现的次数</span><br><span class="line">        // 开始计数</span><br><span class="line">        if (wordCountMap.containsKey(word)) &#123;</span><br><span class="line">            Integer integer = wordCountMap.get(word);</span><br><span class="line">            wordCountMap.put(word, integer + Integer.parseInt(num));</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            wordCountMap.put(word, Integer.parseInt(num));</span><br><span class="line">        &#125;</span><br><span class="line">        // 打印整个map</span><br><span class="line">        System.out.println(wordCountMap);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">        // 不发送数据，所以不用实现。</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>结果分析</strong></p>
<p><a href="https://manzhong.github.io/images/storm/wc.png" target="_blank" rel="noopener"><img src="https://manzhong.github.io/images/storm/wc.png" alt="img"></a></p>
<h2 id="三-集群安装"><a href="#三-集群安装" class="headerlink" title="三 集群安装"></a>三 集群安装</h2><p><strong>1上传解压</strong></p>
<p>修改配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/hosts</span><br><span class="line"></span><br><span class="line">192.168.140.128 node01 zk01 kafka01 storm01</span><br><span class="line">192.168.140.129 node02 zk02 kafka02 storm02</span><br><span class="line">192.168.140.130 node03 zk03 kafka03 storm03 mysql</span><br></pre></td></tr></table></figure>

<p>修改 storm文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cd  storm/conf</span><br><span class="line">rm storm.yaml</span><br><span class="line">vim storm.yaml</span><br><span class="line"></span><br><span class="line">storm.zookeeper.servers:</span><br><span class="line">     - &quot;zk01&quot;</span><br><span class="line">     - &quot;zk02&quot;</span><br><span class="line">     - &quot;zk03&quot;</span><br><span class="line">nimbus.seeds: [&quot;storm01&quot;, &quot;storm02&quot;, &quot;storm03&quot;]</span><br><span class="line">storm.local.dir: &quot;/export/data/storm&quot; </span><br><span class="line">supervisor.slots.ports:</span><br><span class="line">    - 6700</span><br><span class="line">    - 6701</span><br><span class="line">    - 6702</span><br><span class="line">    - 6703</span><br><span class="line">    </span><br><span class="line">    然后把这个storm 发给其他节点</span><br></pre></td></tr></table></figure>

<p>启动:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">后台启动   cd bin</span><br><span class="line">主节点  nohup ./storm nimbus &amp;</span><br><span class="line">其他节点  nohup ./storm supervisor &amp;</span><br><span class="line">然后主节点  启动UI   nohup ./storm ui &amp;</span><br></pre></td></tr></table></figure>

<p>把以上代码提交到集群运行</p>
<p>修改代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在驱动类中  修改提交方式是提交的集群  </span><br><span class="line">在读取文件的勒种  修改文件位置为集群上的</span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar jar包名  驱动类名(包韩路径信息)</span><br></pre></td></tr></table></figure>

</div><div class="post-copyright"><blockquote><p>Ursprünglicher Autor: hechao</p><p>Ursprünglicher Link: <a href="http://yoursite.com/2017/06/24/Storm/">http://yoursite.com/2017/06/24/Storm/</a></p><p>Copyright-Erklärung: Bitte geben Sie die Quelle des Nachdrucks an.</p></blockquote></div><div class="tags"></div><div class="post-share"><div class="social-share"><span>Aktie:</span></div></div><div class="post-nav"><a href="/2017/07/05/Impala/" class="pre">Impala</a><a href="/2017/06/09/Hbase增强/" class="next">Hbase增强</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">Inhalte</i></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#离线处理与实时处理"><span class="toc-text">离线处理与实时处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-实现实时计算系统需要解决那些问题"><span class="toc-text">1.1 实现实时计算系统需要解决那些问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-离线计算是什么"><span class="toc-text">1.1 离线计算是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#流式计算是什么"><span class="toc-text">流式计算是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#离线计算与实时计算的区别"><span class="toc-text">离线计算与实时计算的区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#一概述"><span class="toc-text">一概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二-架构"><span class="toc-text">二 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三-集群安装"><span class="toc-text">三 集群安装</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> Letzte</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/08/24/sparkSql高级/">sparkSql高级</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/20/sparkSQL/">sparkSQL</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/18/spark原理分析2/">spark原理分析2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/10/spark原理分析/">spark原理分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/08/SparkRDD/">SparkRDD</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/08/Spark入门/">Spark入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/shell/">shell</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/18/Scala高级/">Scala高级</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/04/Yarn-资源调度/">Yarn-资源调度</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/27/Scala进阶2/">Scala进阶2</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> Tags</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> Archiv</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Sitemap</a> |  <a href="/atom.xml">Abonnieren Sie diese Site</a> |  <a href="/about/">Kontaktieren Sie den Blogger</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">hechao.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.4"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.4" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>