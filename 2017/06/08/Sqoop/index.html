<!DOCTYPE html><html lang="hc-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="一只沙皮狗的悲伤"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style-dark.css?v=2.0.4"><link rel="stylesheet" type="text/css" href="/css/highlight-dark.css?v=2.0.4"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>Sqoop | 一只沙皮狗的悲伤</title></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Sqoop</h1><a id="logo" href="/.">一只沙皮狗的悲伤</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Suche"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Sqoop</h1><div class="post-meta"><a href="/2017/06/08/Sqoop/#comments" class="comment-count"></a><p><span class="date">Jun 08, 2017</span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>Schlägt</i></i></span></p></div><div class="post-content"><h1 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h1><h1 id="一-简介"><a href="#一-简介" class="headerlink" title="一 简介"></a>一 简介</h1><p>Apache Sqoop是在Hadoop生态体系和RDBMS体系之间传送数据的一种工具。</p>
<p> Sqoop工作机制是将导入或导出命令翻译成mapreduce程序来实现。在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。</p>
<p>Hadoop生态系统包括：HDFS、Hive、Hbase等</p>
<p>RDBMS体系包括(关系型数据库)：Mysql、Oracle、DB2等</p>
<p>Sqoop也可以理解为：“SQL 到 Hadoop 和 Hadoop 到SQL”。</p>
<p>站在Apache的立场数据可以分为导入和导出:</p>
<p>Import：数据导入。RDBMS—–&gt;Hadoop</p>
<p>Export：数据导出。Hadoop—-&gt;RDBMS</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>前提: 安装过java和Hadoop</p>
<p>版本 1.4.6</p>
<p>解压及安装</p>
<p>配置sqoop中的conf中的</p>
<p>mv sqoop-env-template.sh sqoop-env.sh</p>
<p>vi sqoop-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_COMMON_HOME= /export/servers/hadoop-2.7.5 </span><br><span class="line">export HADOOP_MAPRED_HOME= /export/servers/hadoop-2.7.5</span><br><span class="line">export HIVE_HOME= /export/servers/hive</span><br><span class="line">##还可以配置hbase等</span><br></pre></td></tr></table></figure>

<p>把数据库的驱动加入 sqoop的lib中</p>
<p>测试:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop list-databases --connect jdbc:mysql://node03:3306/ --username root --password 123456</span><br></pre></td></tr></table></figure>

<p>本命令会列出所有(mysql)(orole)等的数据库。</p>
<h1 id="二-sqoop的导入"><a href="#二-sqoop的导入" class="headerlink" title="二 sqoop的导入"></a>二 sqoop的导入</h1><h2 id="1-从数据库导入hdfs"><a href="#1-从数据库导入hdfs" class="headerlink" title="1 从数据库导入hdfs"></a>1 从数据库导入hdfs</h2><ul>
<li>mysql的地址尽量不要使用localhost 请使用ip或者host</li>
<li>如果不指定 导入到hdfs默认分隔符是 “,”</li>
<li>可以通过– fields-terminated-by ‘\ t‘ 指定具体的分隔符</li>
<li>如果表的数据比较大 可以并行启动多个maptask执行导入操作，如果表没有主键，请指定根据哪个字段进行切分</li>
</ul>
<p>全量导入</p>
<p><strong>若是换行 每行结尾必须加 \ 否则报错</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /sqoopresult1 \   ##指定存在hdfs的目录</span><br><span class="line">--table emp --m 1   ###指定要导入的表  并指定要运行几个MapTask --m 1</span><br></pre></td></tr></table></figure>

<p>指定分隔符导入 sqoop的默认分隔符为 “,”</p>
<p>–fields-terminated-by ‘\t’ \ ##指定存在hdfs 上的文件的分隔符</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /sqoopresout2 \</span><br><span class="line">--fields-terminated-by &apos;\t&apos; \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>

<p>指定分割字段和启动几个MapReduce</p>
<p>sqoop命令中，–split-by<br>id通常配合-m 10参数使用。用于指定根据哪个字段进行划分并启动多少个maptask。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /sqoopresult214 \</span><br><span class="line">--fields-terminated-by &apos;\t&apos; \</span><br><span class="line">--split-by id \                 ##指定分割字段</span><br><span class="line">--table emp --m 2               ##--m 2 启动两个maptask</span><br></pre></td></tr></table></figure>

<p>##2从数据库导入hive</p>
<p>全量导入</p>
<h3 id="1将表结构复制到hive中"><a href="#1将表结构复制到hive中" class="headerlink" title="1将表结构复制到hive中"></a>1将表结构复制到hive中</h3><p>hive 中的数据库为test 必须存在 emp_add_sp表 可以不存在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop create-hive-table \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table emp_add \</span><br><span class="line">--hive-table test.emp_add_sp</span><br></pre></td></tr></table></figure>

<p>从关系数据库导入文件到hive中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table emp_add \</span><br><span class="line">--hive-table test.emp_add_sp \</span><br><span class="line">--hive-import \</span><br><span class="line">--m 1</span><br></pre></td></tr></table></figure>

<h3 id="2直接从数据库导入数据到hive中-包括表结构和数据"><a href="#2直接从数据库导入数据到hive中-包括表结构和数据" class="headerlink" title="2直接从数据库导入数据到hive中 包括表结构和数据"></a>2直接从数据库导入数据到hive中 包括表结构和数据</h3><p>不用指定hive的表名,会根据数据库的表名自动创建 若test库不存在会在root下创建表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table emp_conn \</span><br><span class="line">--hive-import \</span><br><span class="line">--m 1 \</span><br><span class="line">--hive-database test</span><br></pre></td></tr></table></figure>

<p>##3导入表数据子集(导入hdfs)</p>
<h3 id="1where条件过滤导入"><a href="#1where条件过滤导入" class="headerlink" title="1where条件过滤导入"></a>1where条件过滤导入</h3><p>–where可以指定从关系数据库导入数据时的查询条件。它执行在数据库服务器相应的SQL查询，并将结果存储在HDFS的目标目录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--where &quot;city=&apos;sec-bad&apos;&quot; \</span><br><span class="line">--target-dir /wherequery \</span><br><span class="line">--table emp_add \</span><br><span class="line">--m 1</span><br></pre></td></tr></table></figure>

<p>###2query查询过滤导入</p>
<p>使用 query sql 语句来进行查找不能加参数–table ;<br>并且必须要添加 where 条件;<br>并且 where 条件后面必须带一个$CONDITIONS 这个字符串;<br>并且这个 sql 语句必须用单引号，不能用双引号;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /query1 \</span><br><span class="line">--query &apos;select id,name,deg from emp where id&gt;1203 and $CONDITIONS&apos; \</span><br><span class="line">--split-by id \</span><br><span class="line">--fields-terminated-by &apos;\001&apos; \</span><br><span class="line">--m 2</span><br></pre></td></tr></table></figure>

<p>sqoop命令中–split-by id通常配合-m 10参数使用。<br>首先sqoop会向关系型数据库比如mysql发送一个命令:select max(id),min(id) from test。<br>然后会把max、min之间的区间平均分为10分，最后10个并行的map去找数据库，导数据就正式开始。</p>
<h2 id="4增量导入"><a href="#4增量导入" class="headerlink" title="4增量导入"></a>4增量导入</h2><h3 id="1-Append-模式"><a href="#1-Append-模式" class="headerlink" title="1 Append,模式"></a>1 Append,模式</h3><p>就是追加导入,在原有的基础上 <strong>根据数值类型字段进行追加导入 大于指定的last-value</strong></p>
<p>例子</p>
<p>先把数据库数据导入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /appendresult \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>

<p>在数据库emp 中在插入两条数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert into `userdb`.`emp` (`id`, `name`, `deg`, `salary`, `dept`) values (&apos;1206&apos;, &apos;allen&apos;, &apos;admin&apos;, &apos;30000&apos;, &apos;tp&apos;);</span><br><span class="line">insert into `userdb`.`emp` (`id`, `name`, `deg`, `salary`, `dept`) values (&apos;1207&apos;, &apos;woon&apos;, &apos;admin&apos;, &apos;40000&apos;, &apos;tp&apos;);</span><br></pre></td></tr></table></figure>

<p>执行追加导入</p>
<p>–incremental append \ 增量导入的模式<br>–check-column id \ 数值类型字段进行追加导入<br>–last-value 1205 最后字段值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table emp --m 1 \</span><br><span class="line">--target-dir /appendresult \</span><br><span class="line">--incremental append \</span><br><span class="line">--check-column id \</span><br><span class="line">--last-value 1205</span><br></pre></td></tr></table></figure>

<h3 id="3-lastmodified模式"><a href="#3-lastmodified模式" class="headerlink" title="3 lastmodified模式"></a>3 lastmodified模式</h3><p>1append模式(附加)</p>
<p>lastmodified 根据时间戳类型字段进行追加 <strong>大于等于</strong>指定的last-value</p>
<ul>
<li>注意在lastmodified 模式下 还分为两种情形：append merge-key</li>
</ul>
<p>关于lastmodified 中的两种模式：</p>
<ul>
<li><p>append 只会追加增量数据到一个新的文件中 并且会产生数据的重复问题</p>
<p>因为默认是从指定的last-value 大于等于其值的数据开始导入</p>
</li>
<li><p>merge-key 把增量的数据合并到一个文件中 处理追加增量数据之外 如果之前的数据有变化修改</p>
<p>也可以进行修改操作 底层相当于进行了一次完整的mr作业。数据不会重复。</p>
</li>
</ul>
<p>数据库建表:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table customertest(id int,name varchar(20),last_mod timestamp default current_timestamp on update current_timestamp);</span><br><span class="line">此处的时间戳设置为在数据的产生和更新时都会发生改变.</span><br></pre></td></tr></table></figure>

<p>插入数据(一个一个插,可以保证last_mod 字段不一样)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">insert into customertest(id,name) values(1,&apos;neil&apos;);</span><br><span class="line">insert into customertest(id,name) values(2,&apos;jack&apos;);</span><br><span class="line">insert into customertest(id,name) values(3,&apos;martin&apos;);</span><br><span class="line">insert into customertest(id,name) values(4,&apos;tony&apos;);</span><br><span class="line">insert into customertest(id,name) values(5,&apos;eric&apos;);</span><br></pre></td></tr></table></figure>

<p>执行命令导入hdfs:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /lastmodifiedresult \</span><br><span class="line">--table customertest --m 1</span><br></pre></td></tr></table></figure>

<p>在mysql中在插入一条数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into customertest(id,name) values(6,&apos;james&apos;)</span><br></pre></td></tr></table></figure>

<p>使用增量导入:</p>
<p>三兄弟:两种导入都要写</p>
<p>–check-column last_mod<br>–incremental lastmodified<br>–last-value “2019-06-05 15:52:58” \</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table customertest \</span><br><span class="line">--target-dir /lastmodifiedresult \</span><br><span class="line">--check-column last_mod \</span><br><span class="line">--incremental lastmodified \</span><br><span class="line">--last-value &quot;2019-06-05 15:52:58&quot; \</span><br><span class="line">--m 1 \</span><br><span class="line">--append    #追加方式  merge-key 和append</span><br></pre></td></tr></table></figure>

<p>查看结果发现:</p>
<p>此处已经会导入我们最后插入的一条记录,但是我们却发现此处插入了2条数据，这是为什么呢？<br>这是因为采用lastmodified模式去处理增量时，会将大于等于last-value值的数据当做增量插入</p>
<p>注意:<br>*<em>使用lastmodified模式进行增量处理要指定增量数据是以append模式(附加)还是merge-key(合并)模式添加 *</em></p>
<p>2merge-key模式(合并)</p>
<p>数据库操作:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update customertest set name = &apos;Neil&apos; where id = 1;</span><br></pre></td></tr></table></figure>

<p>增量导入:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table customertest \</span><br><span class="line">--target-dir /lastmodifiedresult \</span><br><span class="line">--check-column last_mod \</span><br><span class="line">--incremental lastmodified \</span><br><span class="line">--last-value &quot;2019-06-05 15:52:58&quot; \</span><br><span class="line">--m 1 \</span><br><span class="line">--merge-key id</span><br></pre></td></tr></table></figure>

<p>由于merge-key模式是进行了一次完整的mapreduce操作，因此最终我们在lastmodifiedresult文件夹下可以看到生成的为part-r-00000这样的文件，会发现id=1的name已经得到修改，同时新增了id=6的数据。</p>
<h1 id="三sqoop导出"><a href="#三sqoop导出" class="headerlink" title="三sqoop导出"></a>三sqoop导出</h1><p>将数据从Hadoop生态体系导出到RDBMS数据库导出前，目标表必须存在于目标数据库中。</p>
<p>export有三种模式：</p>
<p>默认操作: 是从将文件中的数据使用INSERT语句插入到表中。若为空表底层为insert一条一条的插入</p>
<p>更新模式：Sqoop将生成UPDATE替换数据库中现有记录的语句。底层为updata</p>
<p>调用模式：Sqoop将为每条记录创建一个存储过程调用。</p>
<p>配置参数:</p>
<ul>
<li>导出文件的分隔符 如果不指定 默认以“,”去切割读取数据文件 –input-fields-terminated-by</li>
<li>如果文件的字段顺序和表中顺序不一致 需要–columns 指定 多个字段之间以”,”</li>
<li>导出的时候需要指定导出数据的目的 export-dir 和导出到目标的表名或者存储过程名</li>
<li>针对空字符串类型和非字符串类型的转换 “\n”</li>
</ul>
<h2 id="1-默认模式导出HDFS数据到mysql"><a href="#1-默认模式导出HDFS数据到mysql" class="headerlink" title="1 默认模式导出HDFS数据到mysql"></a>1 默认模式导出HDFS数据到mysql</h2><p>默认情况下，sqoop export将每行输入记录转换成一条INSERT语句，添加到目标数据库表中。如果数据库中的表具有约束条件（例如，其值必须唯一的主键列）并且已有数据存在，则必须注意避免插入违反这些约束条件的记录。如果INSERT语句失败，导出过程将失败。<strong>此模式主要用于将记录导出到可以接收这些结果的空表中</strong>。通常用于全表数据导出。</p>
<p>导出时可以是将Hive表中的全部记录或者HDFS数据（可以是全部字段也可以部分字段）导出到Mysql目标表。</p>
<p>1准备hdfs数据</p>
<p>在HDFS文件系统中“/emp/”目录的下创建一个文件emp_data.txt：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1201,gopal,manager,50000,TP</span><br><span class="line">1202,manisha,preader,50000,TP</span><br><span class="line">1203,kalil,php dev,30000,AC</span><br><span class="line">1204,prasanth,php dev,30000,AC</span><br><span class="line">1205,kranthi,admin,20000,TP</span><br><span class="line">1206,satishp,grpdes,20000,GR</span><br></pre></td></tr></table></figure>

<p>2手动创建数据库中的表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE userdb;</span><br><span class="line">mysql&gt; CREATE TABLE employee ( </span><br><span class="line">   id INT NOT NULL PRIMARY KEY, </span><br><span class="line">   name VARCHAR(20), </span><br><span class="line">   deg VARCHAR(20),</span><br><span class="line">   salary INT,</span><br><span class="line">   dept VARCHAR(10));</span><br></pre></td></tr></table></figure>

<p>3执行导出命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table employee \</span><br><span class="line">--export-dir /emp/</span><br></pre></td></tr></table></figure>

<p>若是数据库中字段与emp_data.txt文件中字段类型一致,上述做法可以 若不一致</p>
<p>当导出数据文件和目标表字段列顺序完全一致的时候上述做法可以 若不一致。以逗号为间隔选择和排列各个列。加一下配置</p>
<p>–columns id,name,deg,salary,dept \ 指定emp_data.txt 中个字段的名字</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table employee1 \</span><br><span class="line">--columns id,name,deg,salary,dept \</span><br><span class="line">--export-dir /emp/</span><br></pre></td></tr></table></figure>

<p>–input-fields-terminated-by ‘\t’</p>
<p>指定文件中的分隔符</p>
<p>–columns</p>
<p>选择列并控制它们的排序。当导出数据文件和目标表字段列顺序完全一致的时候可以不写。否则以逗号为间隔选择和排列各个列。没有被包含在–columns后面列名或字段要么具备默认值，要么就允许插入空值。否则数据库会拒绝接受sqoop导出的数据，导致Sqoop作业失败</p>
<p>–export-dir 导出目录，在执行导出的时候，必须指定这个参数，同时需要具备–table或–call参数两者之一，–table是指的导出数据库当中对应的表，</p>
<p>–call是指的某个存储过程。</p>
<p>–input-null-string –input-null-non-string</p>
<p>如果没有指定第一个参数，对于字符串类型的列来说，“NULL”这个字符串就回被翻译成空值，如果没有使用第二个参数，无论是“NULL”字符串还是说空字符串也好，对于非字符串类型的字段来说，这两个类型的空串都会被翻译成空值。比如：</p>
<p>–input-null-string “\N” –input-null-non-string “\N”</p>
<h2 id="2更新导出（updateonly模式）"><a href="#2更新导出（updateonly模式）" class="headerlink" title="2更新导出（updateonly模式）"></a>2更新导出（updateonly模式）</h2><p>– update-key，更新标识，即根据某个字段进行更新，例如id，可以指定多个更新标识的字段，多个字段之间用逗号分隔。</p>
<p>– updatemod，指定updateonly（默认模式），<strong>仅仅更新已存在的数据记录，不会插入新纪录。</strong></p>
<p>在HDFS文件系统中“/updateonly_1/”目录的下创建一个文件updateonly_1.txt：<br>1201,gopal,manager,50000<br>1202,manisha,preader,50000<br>1203,kalil,php dev,30000</p>
<p>手动创建mysql中的目标表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE userdb;</span><br><span class="line">mysql&gt; CREATE TABLE updateonly ( </span><br><span class="line">   id INT NOT NULL PRIMARY KEY, </span><br><span class="line">   name VARCHAR(20), </span><br><span class="line">   deg VARCHAR(20),</span><br><span class="line">   salary INT);</span><br></pre></td></tr></table></figure>

<p>先执行全部导出操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table updateonly \</span><br><span class="line">--export-dir /updateonly_1/</span><br></pre></td></tr></table></figure>

<p>新增一个文件updateonly_2.txt：修改了前三条数据并且新增了一条记录<br>1201,gopal,manager,1212<br>1202,manisha,preader,1313<br>1203,kalil,php dev,1414<br>1204,allen,java,1515</p>
<p>hadoop fs -put updateonly_2.txt /updateonly_2</p>
<p>执行更新导出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table updateonly \</span><br><span class="line">--export-dir /updateonly_2/ \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode updateonly</span><br></pre></td></tr></table></figure>

<h2 id="3-更新导出（allowinsert模式）"><a href="#3-更新导出（allowinsert模式）" class="headerlink" title="3 更新导出（allowinsert模式）"></a>3 更新导出（allowinsert模式）</h2><p>– update-key，更新标识，即根据某个字段进行更新，例如id，可以指定多个更新标识的字段，多个字段之间用逗号分隔。</p>
<p>– updatemod，指定allowinsert，更新已存在的数据记录，同时插入新纪录。<strong>实质上是一个insert &amp; update的操作。</strong></p>
<p>在HDFS “/allowinsert_1/”目录的下创建一个文件allowinsert_1.txt：<br>1201,gopal,manager,50000<br>1202,manisha,preader,50000<br>1203,kalil,php dev,30000</p>
<p>手动创建mysql中的目标表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE userdb;</span><br><span class="line">mysql&gt; CREATE TABLE allowinsert ( </span><br><span class="line">   id INT NOT NULL PRIMARY KEY, </span><br><span class="line">   name VARCHAR(20), </span><br><span class="line">   deg VARCHAR(20),</span><br><span class="line">   salary INT);</span><br></pre></td></tr></table></figure>

<p>先执行全部导出操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table allowinsert \</span><br><span class="line">--export-dir /allowinsert_1/</span><br></pre></td></tr></table></figure>

<p>allowinsert_2.txt。修改了前三条数据并且新增了一条记录。上传至/ allowinsert_2/目录下：<br>1201,gopal,manager,1212<br>1202,manisha,preader,1313<br>1203,kalil,php dev,1414<br>1204,allen,java,1515</p>
<p>执行更新导出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root --password 123456 \</span><br><span class="line">--table allowinsert \</span><br><span class="line">--export-dir /allowinsert_2/ \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode allowinsert</span><br></pre></td></tr></table></figure>

<h1 id="四sqoop-job-作业"><a href="#四sqoop-job-作业" class="headerlink" title="四sqoop job 作业"></a>四sqoop job 作业</h1><h2 id="1-job-语法"><a href="#1-job-语法" class="headerlink" title="1 job 语法"></a>1 job 语法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sqoop job (generic-args) (job-args)</span><br><span class="line">   [-- [subtool-name] (subtool-args)]</span><br><span class="line"></span><br><span class="line">$ sqoop-job (generic-args) (job-args)</span><br><span class="line">   [-- [subtool-name] (subtool-args)]</span><br></pre></td></tr></table></figure>

<h2 id="2-创建job"><a href="#2-创建job" class="headerlink" title="2 创建job"></a>2 创建job</h2><p>在这里，我们创建一个名为jobtest，这可以从RDBMS表的数据导入到HDFS作业。</p>
<p>下面的命令用于创建一个从DB数据库的emp表导入到HDFS文件的作业。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --create jobtest -- import --connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /sqoopresult333 \</span><br><span class="line">--table emp --m 1</span><br><span class="line"></span><br><span class="line">注意import前要有空格</span><br></pre></td></tr></table></figure>

<h2 id="3-验证job"><a href="#3-验证job" class="headerlink" title="3 验证job"></a>3 验证job</h2><p><strong>–list’</strong> 参数是用来验证保存的作业。下面的命令用来验证保存Sqoop作业的列表。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --list</span><br></pre></td></tr></table></figure>

<h2 id="4检查job"><a href="#4检查job" class="headerlink" title="4检查job"></a>4检查job</h2><p><strong>‘–show’</strong> 参数用于检查或验证特定的工作，及其详细信息。以下命令和样本输出用来验证一个名为jobtest的作业。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --show jobtest</span><br></pre></td></tr></table></figure>

<h2 id="5-执行job"><a href="#5-执行job" class="headerlink" title="5 执行job"></a>5 执行job</h2><p><strong>‘–exec’</strong> 选项用于执行保存的作业。下面的命令用于执行保存的作业称为jobtest。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --exec jobtest</span><br></pre></td></tr></table></figure>

<h2 id="6免密执行job"><a href="#6免密执行job" class="headerlink" title="6免密执行job"></a>6免密执行job</h2><p>sqoop在创建job时，使用–password-file参数，可以避免输入mysql密码，如果使用–password将出现警告，并且每次都要手动输入密码才能执行job，sqoop规定密码文件必须存放在HDFS上，并且权限必须是400。</p>
<p>并且检查sqoop的sqoop-site.xml是否存在如下配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;name&gt;sqoop.metastore.client.record.password&lt;/name&gt;</span><br><span class="line"></span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line"></span><br><span class="line">    &lt;description&gt;If true, allow saved passwords in the metastore.</span><br><span class="line"></span><br><span class="line">    &lt;/description&gt;</span><br><span class="line"></span><br><span class="line">&lt;/property&gt;</span><br><span class="line">bin/sqoop job --create jobtest -- import --connect jdbc:mysql://node03:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password-file /input/sqoop/pwd/mysqltest.pwd \</span><br><span class="line">--target-dir /sqoopresult333 \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure></div><div class="post-copyright"><blockquote><p>Ursprünglicher Autor: hechao</p><p>Ursprünglicher Link: <a href="http://yoursite.com/2017/06/08/Sqoop/">http://yoursite.com/2017/06/08/Sqoop/</a></p><p>Copyright-Erklärung: Bitte geben Sie die Quelle des Nachdrucks an.</p></blockquote></div><div class="tags"></div><div class="post-share"><div class="social-share"><span>Aktie:</span></div></div><div class="post-nav"><a href="/2017/06/09/Hbase增强/" class="pre">Hbase增强</a><a href="/2017/05/23/Zookeeper/" class="next">Zookeeper</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">Inhalte</i></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Sqoop"><span class="toc-text">Sqoop</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#一-简介"><span class="toc-text">一 简介</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#安装"><span class="toc-text">安装</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二-sqoop的导入"><span class="toc-text">二 sqoop的导入</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-从数据库导入hdfs"><span class="toc-text">1 从数据库导入hdfs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1将表结构复制到hive中"><span class="toc-text">1将表结构复制到hive中</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2直接从数据库导入数据到hive中-包括表结构和数据"><span class="toc-text">2直接从数据库导入数据到hive中 包括表结构和数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1where条件过滤导入"><span class="toc-text">1where条件过滤导入</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4增量导入"><span class="toc-text">4增量导入</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Append-模式"><span class="toc-text">1 Append,模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-lastmodified模式"><span class="toc-text">3 lastmodified模式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三sqoop导出"><span class="toc-text">三sqoop导出</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-默认模式导出HDFS数据到mysql"><span class="toc-text">1 默认模式导出HDFS数据到mysql</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2更新导出（updateonly模式）"><span class="toc-text">2更新导出（updateonly模式）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-更新导出（allowinsert模式）"><span class="toc-text">3 更新导出（allowinsert模式）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#四sqoop-job-作业"><span class="toc-text">四sqoop job 作业</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-job-语法"><span class="toc-text">1 job 语法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-创建job"><span class="toc-text">2 创建job</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-验证job"><span class="toc-text">3 验证job</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4检查job"><span class="toc-text">4检查job</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-执行job"><span class="toc-text">5 执行job</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6免密执行job"><span class="toc-text">6免密执行job</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> Letzte</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/08/24/sparkSql高级/">sparkSql高级</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/20/sparkSQL/">sparkSQL</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/18/spark原理分析2/">spark原理分析2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/10/spark原理分析/">spark原理分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/08/SparkRDD/">SparkRDD</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/08/Spark入门/">Spark入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/shell/">shell</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/18/Scala高级/">Scala高级</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/04/Yarn-资源调度/">Yarn-资源调度</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/27/Scala进阶2/">Scala进阶2</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> Tags</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> Archiv</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Sitemap</a> |  <a href="/atom.xml">Abonnieren Sie diese Site</a> |  <a href="/about/">Kontaktieren Sie den Blogger</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">hechao.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.4"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.4" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>